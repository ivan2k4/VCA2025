{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6RwsjZnVg4L"
   },
   "source": [
    "# Carga de dataset personalizado para segmentación\n",
    "\n",
    "Además de los datasets de Torchvision, PyTorch proporciona herramientas para la carga de datasets personalizados. Para ello, crearemos una clase que herede de [Dataset](https://pytorch.org/docs/stable/data.html#map-style-datasets) y sobreescribiremos los métodos [`__len__()`](https://docs.python.org/3.7/reference/datamodel.html#object.__len__) y [`__getitem__()`](https://docs.python.org/3.7/reference/datamodel.html#object.__getitem__). \n",
    "\n",
    "En este caso crearemos un dataset personalizado para la segmentación a partir del dataset [__[Mouse Embryos](https://bbbc.broadinstitute.org/BBBC003)__], que contiene un conjunto de 15 imágenes con sus respectivas máscaras de segmentación manuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3110,
     "status": "ok",
     "timestamp": 1675172855259,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "5GiAj8eaVgKE",
    "outputId": "1b5be8bb-7cff-445b-edf5-432ce49e5874"
   },
   "outputs": [],
   "source": [
    "# Connect to drive\n",
    "\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "route = '/content/gdrive/MyDrive/GIA/PVC/P0'\n",
    "\n",
    "print('\\nChange the directory to project route')\n",
    "%cd $route\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1675172855262,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "5Xml59v10pKK"
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "class EmbryoDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, image_path, mask_path, transform = None):\n",
    "        super().__init__()\n",
    "        # Load all the filenames with extension jpg from the image_path directory\n",
    "        self.img_files = glob.glob(os.path.join(image_path, '*.jpg'))\n",
    "        self.mask_files = []    \n",
    "                \n",
    "        # Load the filenames of the masks (it is assumed that each mask\n",
    "        # has the same name as the corresponding image).\n",
    "        for img_path in self.img_files:\n",
    "             self.mask_files.append(os.path.join(mask_path,os.path.basename(img_path)))\n",
    "                \n",
    "        if transform:\n",
    "          self.transform = transform\n",
    "        else:\n",
    "          self.transform = transforms.Compose([\n",
    "                                                transforms.ToPILImage(),\n",
    "                                                transforms.ToTensor()])\n",
    "\n",
    "\n",
    "    # Returns the n-th image with its corresponding mask and image name\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_files[index]\n",
    "        mask_path = self.mask_files[index]\n",
    "\n",
    "        # Get label from imagename\n",
    "        name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "\n",
    "        # Get image and mask\n",
    "        image = read_image(img_path)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        mask = read_image(mask_path)\n",
    "        mask = self.transform(mask)\n",
    "\n",
    "        return image, mask, name\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9K0J7QSuA-p7"
   },
   "source": [
    "Funciones auxiliares para convertir un tensor de torch en una matriz numpy y la visualización de una imagen con su máscara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1675172855263,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "PE50tGBBBGZp"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    new_image = np.empty( (tensor.size()[1], tensor.size()[2]) )\n",
    "    new_image[:,:] = tensor[0,:,:]\n",
    "    return new_image\n",
    "\n",
    "def show(image, mask, title=None):\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    ax[0].imshow(image, cmap=\"gray\")\n",
    "    ax[0].axis('off')\n",
    "    if title is not None:\n",
    "        fig.suptitle(title)\n",
    "    ax[1].imshow(mask, cmap=\"gray\")\n",
    "    ax[1].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kNWKTo63xQs"
   },
   "source": [
    "Carga de dataset sin data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1675172855263,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "Ucy3S0KH3xfi",
    "outputId": "982cef2f-cafe-4276-9238-75c232adaddc"
   },
   "outputs": [],
   "source": [
    "\n",
    "         \n",
    "simple_dataset = EmbryoDataset(f\"{route}/Embryo/images\", f\"{route}/Embryo/masks\")\n",
    "print(len(simple_dataset))\n",
    "\n",
    "# Visualize a sample\n",
    "image, mask, name = simple_dataset[0]\n",
    "show(tensor_to_image(image), tensor_to_image(mask), title=f\"Sample {name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3bPDVpv5oVj"
   },
   "source": [
    "Carga de dataset con data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1675172870424,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "NkFtYSC57GRd",
    "outputId": "0bf036a0-48fc-4f71-c903-3b9bdf4e0c82"
   },
   "outputs": [],
   "source": [
    "aug_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.CenterCrop(416),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "aug_dataset = EmbryoDataset(f\"{route}/Embryo/images\", f\"{route}/Embryo/masks\", aug_transforms)\n",
    "\n",
    "\n",
    "# Visualize a sample\n",
    "image, mask, name = aug_dataset[0]\n",
    "show(tensor_to_image(image), tensor_to_image(mask), title=f\"Sample {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrS_EnyWDKrb"
   },
   "source": [
    "División del conjunto de datos en entrenamiento y test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1675172878476,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "rT4eL7Dn5ohS",
    "outputId": "f26dc45b-8cd2-4231-c5cc-b26673fa211e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "TEST_RATIO = 0.2\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "num_train = int((1.0 - TEST_RATIO) * len(simple_dataset))\n",
    "num_test = len(simple_dataset) - num_train\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_set, test_set = torch.utils.data.random_split(simple_dataset, [num_train, num_test])\n",
    "\n",
    "# Loader for train and validation sets\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE,\n",
    "                                            shuffle=True, num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=False, num_workers=8)\n",
    "\n",
    "print(len(simple_dataset), len(train_loader), len(test_loader))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
