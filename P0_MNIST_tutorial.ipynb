{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrpdQ7YkgnU6"
   },
   "source": [
    "# Conexión a Google Drive\n",
    "\n",
    "El primer paso es obtener acceso al almacenamiento para la práctica. Utilizaremos un directorio ubicado en nuestro Google Drive, por ejemplo `\"GIA/VCA/P0/\"`.\n",
    "\n",
    "En primer lugar, conectamos el notebook con nuestro Google Drive. Ejecutamos `drive.mount` con una ruta y nos pedirá autorización para acceder a los contenidos. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2491,
     "status": "ok",
     "timestamp": 1675164493883,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "hHw8R15NcBiX",
    "outputId": "3fb0385e-c364-4784-8623-d172893ee255"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/gdrive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__JCYxbKlOhS"
   },
   "source": [
    "Después podemos cambiar el directorio de trabajo a la ruta del proyecto, como `\"GIA/VCA/P0/\"` en nuestro Drive. Esto nos permitirá utilizar rutas relativas para acceder a nuestros datos y guardar resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1675169647561,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "fZ4SaRjfdPnz",
    "outputId": "b135656d-0a84-40d2-e578-8508ecda55cf"
   },
   "outputs": [],
   "source": [
    "# route = '/content/gdrive/MyDrive/GIA/VCA/P0'\n",
    "\n",
    "# print(\"Current directory:\")\n",
    "# !pwd\n",
    "\n",
    "# print(f\"\\nWe now change the directory to '{route}'\")\n",
    "# %cd $route\n",
    "# !pwd\n",
    "\n",
    "# print(\"\\nAnd here there are our files:\")\n",
    "# !ls -lasth\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAkFlv-VofgR"
   },
   "source": [
    "# Cargar un dataset de torchvision\n",
    "\n",
    "La biblioteca torchvision contiene varios [datasets de imágenes](https://pytorch.org/vision/stable/datasets.html) listos para usar. Nosotros cargaremos y utilizaremos el dataset de clasificación de dígitos [MNIST](https://pytorch.org/vision/stable/datasets.html#mnist).\n",
    "\n",
    "La API permite descargarlo directamente en una ruta determinada. Utilizaremos el directorio del proyecto que hemos almacenado en la variable `route`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "V7tCHI_NaCkC"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[0;32m      3\u001b[0m train \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mMNIST(route, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m test \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mMNIST(route, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "train = datasets.MNIST(route, train=True, download=True)\n",
    "test = datasets.MNIST(route, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWk87PY2pa5L"
   },
   "source": [
    "Ahora el conjunto de datos está listo para usarse a partir de los objetos `test` y `train`, que son una subclase de [Dataset](https://pytorch.org/docs/stable/data.html#map-style-datasets), y definirá una función *pythonic* [`__getitem__()`](https://docs.python.org/3.7/reference/datamodel.html#object.__getitem__) que permita iterar sobre él, y normalmente una [`__len__()`](https://docs.python.org/3.7/reference/datamodel.html#object.__len__) que permite obtener su tamaño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 795,
     "status": "ok",
     "timestamp": 1675163759084,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "qWzXmpdHpaXT",
    "outputId": "a2aaa2f9-b122-47fc-ccce-9ca47a54c174"
   },
   "outputs": [],
   "source": [
    "print(train)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 627
    },
    "executionInfo": {
     "elapsed": 1616,
     "status": "ok",
     "timestamp": 1675164555780,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "WFWHeCjSjJRP",
    "outputId": "9243bb36-95e0-4463-9df1-7b8892fa08e9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy import random\n",
    "\n",
    "print(len(test))\n",
    "print(test[0])\n",
    "\n",
    "cols, rows = 8, 5\n",
    "figure = plt.figure(figsize=(cols*2, rows*2))\n",
    "view = random.permutation(cols * rows + 1)\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample, label = test[view[i]]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(f'Clase {label}')\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(sample, cmap=\"gray\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2jIm9tn7QcN"
   },
   "source": [
    "# Carga de un modelo de torchvision\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAqJitik8Ozm"
   },
   "source": [
    "Torchvision también contiene varios [modelos de arquitecturas de red](https://pytorch.org/vision/stable/models.html) con los pesos preentrenados y listos para usar. Cargaremos y utilizaremos el modelo [VGG-16](https://pytorch.org/vision/stable/models.html#id2), que está preentrenado en el dataset ImageNet.\n",
    "\n",
    "También podemos cargar el modelo con pesos aleatorios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1858,
     "status": "ok",
     "timestamp": 1675163761857,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "MjZ9IWH8V75P",
    "outputId": "10c4a9b8-27d6-4793-f9ec-00e040a3d0fa"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "vgg = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wr0NKC2s_ulM"
   },
   "source": [
    "Ahora podemos explorar, modificar y utilizar el modelo cargado.\n",
    "\n",
    "Este modelo se compone de bloques de dos/tres capas [Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d) 3x3 de N canales, seguidos de activación [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU), y una capa final [MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d) que divide la imagen por 2. Hay 5 bloques de este tipo, con número de canales duplicado desde N=64 hasta N=512. El bloque convolucional se almacena en un módulo [Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential) llamado `features`.\n",
    "\n",
    "La cabeza del clasificador también se almacena en un módulo [Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential) (`classifier`). El modelo espera un vector de entrada de 25.088 características, que resulta de aplicar el módulo de características a una imagen de 128x128 (512x7x7). Este modelo se compone de varias capas [Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) totalmente conectadas, seguidas de activación [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU) y [Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout). La capa de salida es una capa [Lineal](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) totalmente conectada con 1000 salidas de clase.\n",
    "\n",
    "Además, esta implementación de PyTorch ofrece las siguientes características:\n",
    "\n",
    "* Una capa [AddaptiveAvgPool2d](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html#torch.nn.AdaptiveAvgPool2d) 7x7 entre la capa convolucional `features` y la capa `classifier` totalmente conectada. Esto permite tener 512x7 características. Por lo tanto, no importa si la imagen de entrada es mayor que 128x128.\n",
    "* La capa de salida es lineal, lo que proporciona los logits de salida para 1000 clases. Para obtener una probabilidad de clasificación debemos añadir una capa [SoftMax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax) o una capa [SoftMax2d](https://pytorch.org/docs/stable/generated/torch.nn.Softmax2d.html#torch.nn.Softmax2d) encima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1675163761858,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "HeEXI-heb9k1",
    "outputId": "71f35e7d-20c9-4235-9830-00965c0c81af"
   },
   "outputs": [],
   "source": [
    "print(vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWWZdVu1HkYJ"
   },
   "source": [
    "Podemos probar la red con imágenes del conjunto de datos MNIST que hemos cargado. No se espera nada útil, ya que la red está entrenada en ImageNet.\n",
    "\n",
    "Sin embargo, esta red espera imágenes RGB de 128x128, y las imágenes MNIST son de 1 canal y 28x28 píxeles. Vamos a redimensionar las imágenes a 128x128 y convertirlas a RGB usando la librería [torchvision.transforms](https://pytorch.org/vision/stable/transforms.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1675163761858,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "rWIq_YFBaeAE",
    "outputId": "45a3119d-288a-4da5-fb9c-dc150a54356a"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms as t\n",
    "\n",
    "trans = t.Compose([\n",
    "                   t.Lambda(lambda x: x.convert(\"RGB\")),\n",
    "                   t.Resize(128),\n",
    "                   t.ToTensor()\n",
    "])\n",
    "\n",
    "input, target = test[0]\n",
    "print(\"This is the dataset 'input'\")\n",
    "print(input)\n",
    "\n",
    "input = trans(input).unsqueeze_(0) \n",
    "# The unsqueeze is because the network need an input of [N,3,W,H], \n",
    "# where N is the number of training/testing images: in this case 1.\n",
    "# The transform output will be a PyTorch tensor of shape [3,128,128].\n",
    "# The unsqueeze gives a tensor of shape [1,3,128,128].\n",
    "\n",
    "print(\"\\nThis is the transformed 'input'\")\n",
    "print(input.shape)\n",
    "\n",
    "output = vgg(input)\n",
    "\n",
    "print(\"\\nThis is the output of the network\")\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhTUwPVwR3uG"
   },
   "source": [
    "#  Adaptar el modelo cargado\n",
    "\n",
    "En este caso modificaremos el modelo para clasificar 10 dígitos. Se aplica una operación de pooling a la salida del bloque convolucional y se añade una capa totalmente conectada de 10 neuronas como salida de la clasificación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1675163761859,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "g-zLVdPFM0-f",
    "outputId": "cc75df1a-9aeb-4dbc-a5e8-b2cf1283e517"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "vggf = vgg.features\n",
    "\n",
    "mymodel = nn.Sequential(\n",
    "    vggf,\n",
    "    nn.AdaptiveAvgPool2d(output_size = 1),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(512, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 10),\n",
    ")\n",
    "\n",
    "output = mymodel(input)\n",
    "print(output.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkP5GMG0WHln"
   },
   "source": [
    "Adicionalmente adaptaremos el número de canales de entrada a 1. Inicializando los nuevos kenels de nivel de gris como la suma a lo largo de los canales de los kenels RGB en la red pre-entrenada.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1675163761859,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "01_1Sm9yWGwm",
    "outputId": "c4502f64-6245-4d6e-b76f-529465f3d9c4"
   },
   "outputs": [],
   "source": [
    "print(mymodel[0][0])\n",
    "for name, param in mymodel[0][0].named_parameters():\n",
    "  print(f\"- {name}: {param.shape}\")\n",
    "\n",
    "old_layer = mymodel[0][0]\n",
    "mymodel[0][0] = nn.Conv2d(1, 64, 3, padding=1)\n",
    "mymodel[0][0].weight.data = old_layer.weight.sum(dim=1, keepdim=True)\n",
    "mymodel[0][0].bias.data = old_layer.bias\n",
    "\n",
    "print(mymodel[0][0])\n",
    "for name, param in mymodel[0][0].named_parameters():\n",
    "  print(f\"- {name}: {param.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgYQbBXtwLAv"
   },
   "source": [
    "# Crear un modelo desde cero\n",
    "\n",
    "Para definir un nuevo modelo desde cero es conveniente definir una subclase de nn.Module.\n",
    "\n",
    "Sólo necesitamos definir el constructor y el método `forward`. El método backward se calcula automáticamente usando `autograd` a partir del grafo de ejecución.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uoJzD4UPzMCn"
   },
   "outputs": [],
   "source": [
    "class myCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(myCNN, self).__init__()\n",
    "        \n",
    "        self.convlayer1 = nn.Sequential(\n",
    "            nn.Conv2d(1,32,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.convlayer2 = nn.Sequential(\n",
    "            nn.Conv2d(32,64,3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(64*6*6,600), # We assume the 6x6 resulting from input images of 28x28\n",
    "            nn.ReLU()\n",
    "            )\n",
    "\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.convlayer1(x)\n",
    "        x = self.convlayer2(x)\n",
    "        x = x.view(-1,64*6*6) # Like flattening in-place\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return nn.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBxm5E5qzLL8"
   },
   "source": [
    "Ahora podemos hacer una instancia de este modelo y jugar con él.\n",
    "\n",
    "Ten en cuenta que las capas se inicializarán con los parámetros aleatorios por defecto, que se pueden cambiar por aproximaciones definidas por el usuario. Por ejemplo, para las capas convolucionales activadas con ReLU, es más conveniente utilizar la inicialización [Kaiming He Uniform](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_uniform_), pero para las capas TanH es mejor seguir la de [Xavier Glorot](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.xavier_uniform_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 486,
     "status": "ok",
     "timestamp": 1675164296885,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "xDWoEsWH1nF9",
    "outputId": "d67dc122-f901-47d6-8053-18177128435e"
   },
   "outputs": [],
   "source": [
    "mycnn = myCNN()\n",
    "\n",
    "print(mycnn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aBdT74h1vBwQ"
   },
   "source": [
    "# Carga de datos para el entrenamiento\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mw9_NlLcwXKS"
   },
   "source": [
    "Los [Datasets](https://pytorch.org/vision/stable/datasets.html#mnist) de PyTorch permiten añadir un conjunto de [transforms](https://pytorch.org/vision/stable/transforms.html) que deben aplicarse a los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oEUZGGFDVEtU"
   },
   "outputs": [],
   "source": [
    "mytransforms = t.Compose([\n",
    "                          t.Resize(64),\n",
    "                          t.ToTensor(),\n",
    "                          t.Normalize((0.5,),(0.5,))\n",
    "])\n",
    "\n",
    "test = datasets.MNIST(route, train=False, download=True, transform = mytransforms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3yyKn4wySOy"
   },
   "source": [
    "Las transformaciones del dataset pueden ser aleatorias, de modo que cada vez que el dataset devuelve una imagen determinada, se aplica una transformación aleatoria. Esto puede utilizarse para aumentar los datos en línea durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 859
    },
    "executionInfo": {
     "elapsed": 2524,
     "status": "ok",
     "timestamp": 1675164334744,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "Z_kTFDUtDjti",
    "outputId": "5ee53b53-5c7c-4064-8097-122277943cf3"
   },
   "outputs": [],
   "source": [
    "myaugmentation = t.Compose([\n",
    "                             t.Pad(4),\n",
    "                             t.RandomAffine(degrees=45, translate=(0.2, 0.2), scale=(0.75,1.25), shear=15),\n",
    "                             t.ColorJitter(brightness=(0.2,0.8), contrast=(0.2, 0.8)),\n",
    "                             mytransforms\n",
    "])\n",
    "\n",
    "train = datasets.MNIST(route, train=True, download=True, transform=myaugmentation)\n",
    "\n",
    "sample_idx = random.randint(0, len(train))\n",
    "cols, rows = 8, 5\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols,figsize =(cols*2, rows*2) )\n",
    "\n",
    "# Loading the same sample over and over again gives different transforms\n",
    "for axrow in axes:\n",
    "  for ax in axrow:\n",
    "    sample,label = train[sample_idx]\n",
    "    ax.imshow(sample[0,...], cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.title.set_text(f'Class {label}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BM3T5gS7xZmO"
   },
   "source": [
    "Además, es conveniente acceder a los conjuntos de datos mediante un [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader). Esto permitirá cargar los datos de forma aleatoria y por lotes, listos para ser utilizados por la red. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 583,
     "status": "ok",
     "timestamp": 1675163765241,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "MbT-pXWEyrN4",
    "outputId": "16d059c0-52d5-4ea3-e025-943cfe63092a"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(train, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "#We can iterate over the dataset as:\n",
    "counter = 0\n",
    "for sample, target in dataloader:\n",
    "  print(f\"Minibacth {counter}: ({sample.shape}, {target.shape}).\")\n",
    "  counter += 1\n",
    "  if counter == 10:\n",
    "    print(\"... It would continue for much longer until an epoch is completed.\")\n",
    "    break\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmtileQivd6I"
   },
   "source": [
    "# Entrenamiento de la red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pk1EK8Fmy0Au"
   },
   "source": [
    "PyTorch incluye un motor de diferenciación automática [autograd](https://pytorch.org/docs/stable/autograd.html). Esto permite calcular fácilmente los gradientes de retropropagación. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1675163765242,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "pKcR9b0Mv0HT",
    "outputId": "8bb293a8-dec6-4c20-c1fc-f34025d3204e"
   },
   "outputs": [],
   "source": [
    "# Autograd Example. Make two tensors and operate with them\n",
    "import torch\n",
    "\n",
    "a = torch.tensor([1., 2.], requires_grad=True)\n",
    "b = torch.tensor([5., 6.], requires_grad=True)\n",
    "\n",
    "# Look at the current gradients\n",
    "print(f\"Tensor 'a': {a}\")\n",
    "print(f\"Gradients wrt tensor 'a': {a.grad}\")\n",
    "\n",
    "print(f\"Tensor 'b': {b}\")\n",
    "print(f\"Gradients wrt tensor 'b': {b.grad}\")\n",
    "\n",
    "# Pass it through the \"network\"\n",
    "\n",
    "q = 3*a**3-b**2           # 3a^3-b^2 -> dq/da = 9a^2 ; dq/db = -2b\n",
    "\n",
    "print(f\"Tensor 'q': {q}\")\n",
    "print(f\"Tensor 'q.sum()': {q.sum()}\")\n",
    "\n",
    "\n",
    "# Compute the backpropagation gradients, first integrating all the q outputs\n",
    "\n",
    "q.sum().backward()\n",
    "\n",
    "print(f\"After backpropagation:\")\n",
    "print(f\"Gradients wrt tensor 'a': {a.grad}; Theoretical gradients: {9*a**2}\")\n",
    "print(f\"Gradients wrt tensor 'b': {b.grad}; Theoretical gradients: {-2*b}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47-FGacJ0FN6"
   },
   "source": [
    "\n",
    "Para completar un bucle de optimización necesitamos una red, una función de pérdida a partir de la cual retropropagar (usaremos la [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)) y también necesitamos un [Optimizer](https://pytorch.org/docs/stable/optim.html), como [Adam](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam), o [SGD](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD), para actualizar los pesos.\n",
    "\n",
    "También es conveniente utilizar la GPU. Para ello, asegúrate de que la máquina virtual de Colab tiene la GPU habilitada en `Runtime>Change runtime type>Hardware accelaration>GPU`. Además necesitamos cargar los tensores en el dispositivo GPU. Este es un bucle de entrenamiento mínimo:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 223061,
     "status": "ok",
     "timestamp": 1675164045341,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "QlusmHZpXkqk",
    "outputId": "0dc17168-973a-4314-9e0a-9104a2e3ea80"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "mymodel.to(device)                     # Place the model into the GPU\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mymodel.parameters(), lr=1e-4)  # Intizalize the optimizer with the network parameters and learning rate\n",
    "\n",
    "for epoch in range(3):                           # Iterate a given number of epochs, or control with another condition\n",
    "  for i,data in enumerate(dataloader):            # Iterate over the batches in the dataset\n",
    "    samples = data[0].to(device)                  # Place the data into the GPU\n",
    "    targets = data[1].to(device)                  # Place the targets into the GPU\n",
    "\n",
    "    output = mymodel(samples)                     # Compute the training samples output\n",
    "    loss = criterion(output, targets)             # Compute the loss\n",
    "\n",
    "    optimizer.zero_grad()                         # Reset the old gradients accumulated in the buffer from previous iteration\n",
    "    loss.backward()                               # Backpropagate the error, which accumulates the gradients for the batch\n",
    "    optimizer.step()                              # Update the model parameters, according to the optimizer rule\n",
    "\n",
    "    if i%200 == 0:\n",
    "      _, predicted = torch.max(output,1)\n",
    "      total = targets.size(0)\n",
    "      correct = (predicted == targets).sum().item()\n",
    "      print(f\"epoch:{epoch}, mini-batch: {i}: Training loss: {loss.item()}, accuracy: {correct/total}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGSi7ifSo5p5"
   },
   "source": [
    "# Test de la red\n",
    "\n",
    "Una vez entrenada la red, podemos realizar un bucle similar para agregar algunas métricas sobre el conjunto de test. Por ejemplo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4451,
     "status": "ok",
     "timestamp": 1675164049783,
     "user": {
      "displayName": "Lucía Ramos García",
      "userId": "01153031010548417511"
     },
     "user_tz": -60
    },
    "id": "6G9yy7H7pG00",
    "outputId": "69716032-d190-4267-8d75-e80795c1ffb0"
   },
   "outputs": [],
   "source": [
    "def accuracy(outputs, targets):\n",
    "    _, predicted = outputs.max(1)\n",
    "    total = targets.size(0)\n",
    "    correct = (predicted == targets).sum().item()\n",
    "    return correct/total\n",
    "\n",
    "testloader = DataLoader(test, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "mymodel.eval() #  This notifies all the layers in the model to put themselves \n",
    "             # into evaluation mode, just in case there are some with different \n",
    "             # behaviour during training and testing\n",
    "\n",
    "mean_acc = 0\n",
    "with torch.no_grad(): # This disables autograd\n",
    "  for i, (samples, targets) in enumerate(testloader):\n",
    "    samples = samples.to(device)\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    outputs = mymodel(samples)\n",
    "    \n",
    "    this_acc = accuracy(outputs, targets)\n",
    "    mean_acc += this_acc\n",
    "\n",
    "  mean_acc /= (i+1)\n",
    "\n",
    "print(f\"Model accuracy on the test set is {mean_acc*100} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZniv56AvODt"
   },
   "source": [
    "# Frameworks y utilidades \n",
    "\n",
    "Aunque PyTorch es lo suficientemente flexible como para diseñar los bucles de entrenamiento y evaluación a voluntad, es conveniente tratar de estructurar tus rutinas de entrenamiento y evaluación en funciones y scripts personalizados que puedan ser fácilmente reutilizados y mantenidos. \n",
    "\n",
    "A veces es conveniente utilizar bibliotecas externas que definan un marco de entrenamiento y evaluación para controlar el bucle de entrenamiento con las mejores prácticas estándar.\n",
    "\n",
    "Esto, sin embargo, requerirá cierta curva de aprendizaje adicional, y a veces es conveniente afrontar los problemas a mano antes de indagar en una solución enlatada (aunque flexible).\n",
    "\n",
    "Algunos ejemplos de frameworks de entrenamiento:\n",
    "\n",
    "* [PyTorch ignite](https://pytorch.org/ignite/): [notebook de ejemplo MNIST](https://colab.research.google.com/github/pytorch/ignite/blob/5e6a629566c411d85a2184ae748cb0312e159150/examples/notebooks/FashionMNIST.ipynb)\n",
    "* [PyTorch lightning](https://www.pytorchlightning.ai/): [notebook de ejemplo MNIST](https://colab.research.google.com/github/PyTorchLightning/pytorch-lightning/blob/fe0d08899eba94d275ff42253f495d9e70d86f89/notebooks/01-mnist-hello-world.ipynb)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
